{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "input_token_index=pickle.load(open('input_token_index.pickle','rb'))\n",
    "output_token_index=pickle.load(open('output_token_index.pickle','rb'))\n",
    "max_encoder_len=15\n",
    "max_decoder_len=58\n",
    "encoder_tokens=pickle.load(open('encoder_tokens.pickle','rb'))\n",
    "decoder_tokens=pickle.load(open('decoder_tokens.pickle','rb'))\n",
    "exclamations=pickle.load(open('exclamations.pickle','rb'))\n",
    "questions=pickle.load(open('questions.pickle','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Failed')\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass\n",
    "\n",
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "\n",
    "latent_dim=256\n",
    "model = tf.keras.models.load_model('Encoder_Decoder_model_french_.h5')\n",
    "\n",
    "encoder_inputs = model.input[0]   # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output   # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]   # input_2\n",
    "decoder_state_input_h = Input(shape=(latent_dim),name='input_3')\n",
    "decoder_state_input_c = Input(shape=(latent_dim),name='input_4')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_punc(user_input):\n",
    "    user_input=user_input.lower()\n",
    "    if (user_input in questions):\n",
    "        user_input=user_input+'?'\n",
    "        return user_input\n",
    "    if (user_input in exclamations):\n",
    "        user_input=user_input+'!'\n",
    "        return user_input\n",
    "    else:\n",
    "        return user_input\n",
    "\n",
    "def get_seq(input_text):\n",
    "    print('Translating: ',input_text)\n",
    "    input_text=find_punc(input_text)\n",
    "    encoder_input=np.zeros((1,max_encoder_len,encoder_tokens),dtype='float32')\n",
    "    for i,char in enumerate(input_text):\n",
    "        encoder_input[0,i,input_token_index[char.lower()]]=1\n",
    "        print('input token index: ',input_token_index[char.lower()])\n",
    "    encoder_input[0,i+1:,input_token_index[' ']]=1\n",
    "    return encoder_input\n",
    "\n",
    "def Translate(input_text):\n",
    "    encoder_input=get_seq(input_text)\n",
    "    states_values=encoder_model.predict(encoder_input)\n",
    "    target_seq = np.zeros((1, 1, decoder_tokens))\n",
    "    target_seq[0, 0, output_token_index['\\t']] = 1.\n",
    "    stop_condition = False\n",
    "    decoded_sentance=''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_values)\n",
    "        sampled_token_index=np.argmax(output_tokens[0,-1,:])\n",
    "        print('sampled token: ',sampled_token_index)\n",
    "        char=list(output_token_index.keys())[list(output_token_index.values()).index(sampled_token_index)]\n",
    "        print('char_predicted: ',char[0])\n",
    "        decoded_sentance+=char[0]\n",
    "        if (char[0] == '\\n' or len(decoded_sentance) > max_decoder_len):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1,decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        states_values=[h,c]\n",
    "    return decoded_sentance[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating:  go\n",
      "input token index:  25\n",
      "input token index:  33\n",
      "sampled token:  4\n",
      "char_predicted:  V\n",
      "sampled token:  31\n",
      "char_predicted:  a\n",
      "sampled token:  53\n",
      "char_predicted:   \n",
      "sampled token:  12\n",
      "char_predicted:  !\n",
      "sampled token:  7\n",
      "char_predicted:  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Va !'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Translate('go')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
